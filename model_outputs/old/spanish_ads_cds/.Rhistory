count <- sum(str_detect(data$X1, re))
count / nrow(data)
}
finnish <- 'http://socsci.uci.edu/~cjmayer/LSCI_202A/finnish.txt'
fin_front <- c('ä', 'ö', 'y')
fin_back <- c('a', 'o', 'u')
uyghur <- 'http://socsci.uci.edu/~cjmayer/LSCI_202A/uyghur.txt'
uyg_front <- c('e', 'ö', 'ü')
uyg_back <- c('a', 'o', 'u')
get_cooccurrence_proportion(finnish, fin_front, fin_back)
get_cooccurrence_proportion(uyghur, uyg_front, uyg_back)
source("C:/Users/conno/Dropbox/ling/LSCI_202A/Grading/ex3/ShivaUpadhye_LSCI202A_Exercise3.R")
print(Finnish_disharmonic_proportion)
print(Uyghur_disharmonic_proportion)
Finnish_disharmonic_proportion <- get_cooccurence_proportion(Finnish_corpus,set1,set2)
corpus_data
corpus_data
print(C)
length(disharmonic_roots)
# 4.1
# Returns disharmonic roots
get_cooccurence_tokens <-function(corpus,set1,set2){
# create regex patterns
set1_str <- str_c(set1,collapse='')
set1_pattern <- str_glue('[{set1_str}]')
set2_str <- str_c(set2,collapse='')
set2_pattern <- str_glue('[{set2_str}]')
# load corpus
corpus_data <- read_csv(corpus,col_names=c('words'))
# extract disharmonic roots into a vector
disharmonic_roots <- corpus_data %>%
filter(str_detect(words,set1_pattern) & str_detect(words,set2_pattern)) %>%
pull(words)
return(disharmonic_roots)
}
# 4.2
# Returns proportion of disharmonic roots in the corpus
get_cooccurence_proportion <- function(corpus,set1,set2){
# load corpus
corpus_data <- read_csv(corpus,col_names=c('words'))
C = dim(corpus_data)[1]
# get disharmonic roots
disharmonic_roots <- get_cooccurence_tokens(corpus,set1,set2)
d = length(disharmonic_roots)
# compute proportion
proportion_disharmonic <- d/C
return(proportion_disharmonic)
}
# 4.1
# Returns disharmonic roots
get_cooccurence_tokens <-function(corpus,set1,set2){
# create regex patterns
set1_str <- str_c(set1,collapse='')
set1_pattern <- str_glue('[{set1_str}]')
set2_str <- str_c(set2,collapse='')
set2_pattern <- str_glue('[{set2_str}]')
# load corpus
corpus_data <- read_csv(corpus,col_names=c('words'))
# extract disharmonic roots into a vector
disharmonic_roots <- corpus_data %>%
filter(str_detect(words,set1_pattern) & str_detect(words,set2_pattern)) %>%
pull(words)
return(disharmonic_roots)
}
# 4.2
# Returns proportion of disharmonic roots in the corpus
get_cooccurence_proportion <- function(corpus,set1,set2){
# load corpus
corpus_data <- read_csv(corpus,col_names=c('words'))
C = dim(corpus_data)[1]
# get disharmonic roots
disharmonic_roots <- get_cooccurence_tokens(corpus,set1,set2)
d = length(disharmonic_roots)
# compute proportion
proportion_disharmonic <- d/C
return(proportion_disharmonic)
}
# Finnish
Finnish_corpus <- 'http://socsci.uci.edu/~cjmayer/LSCI_202A/finnish.txt'
# Front vowels in Finnish
set1 <- c('y','Ã¶','Ã¤')
# Back vowels in Finnish
set2 <- c('u','o','a')
Finnish_disharmonic_roots <- get_cooccurence_tokens(Finnish_corpus,set1,set2)
length(Finnish_disharmonic_roots)
get_cooccurence_tokens <-function(corpus,set1,set2){
# create regex patterns
set1_str <- str_c(set1,collapse='')
set1_pattern <- str_glue('[{set1_str}]')
set2_str <- str_c(set2,collapse='')
set2_pattern <- str_glue('[{set2_str}]')
# load corpus
corpus_data <- read_csv(corpus,col_names=c('words'))
# extract disharmonic roots into a vector
disharmonic_roots <- corpus_data %>%
filter(str_detect(words,set1_pattern) & str_detect(words,set2_pattern)) %>%
pull(words)
return(disharmonic_roots)
}
# 4.2
# Returns proportion of disharmonic roots in the corpus
get_cooccurence_proportion <- function(corpus,set1,set2){
# load corpus
corpus_data <- read_csv(corpus,col_names=c('words'))
C = dim(corpus_data)[1]
# get disharmonic roots
disharmonic_roots <- get_cooccurence_tokens(corpus,set1,set2)
d = length(disharmonic_roots)
# compute proportion
proportion_disharmonic <- d/C
return(proportion_disharmonic)
}
# Finnish
Finnish_corpus <- 'http://socsci.uci.edu/~cjmayer/LSCI_202A/finnish.txt'
# Front vowels in Finnish
set1 <- c('y','ö','ä')
# Back vowels in Finnish
set2 <- c('u','o','a')
Finnish_disharmonic_roots <- get_cooccurence_tokens(Finnish_corpus,set1,set2)
Finnish_disharmonic_proportion <- get_cooccurence_proportion(Finnish_corpus,set1,set2)
print(Finnish_disharmonic_proportion)
length(Finnish_disharmonic_roots)
get_cooccurrence_tokens <- function(corpus, set1, set2){
re1 <- str_glue("[{str_c(set1, collapse='')}]")
re2 <- str_glue("[{str_c(set2, collapse='')}]")
corpus %>%
str_subset(re1) %>%
str_subset(re2)
}
# Q4.3
finnish <- read.table(url("http://socsci.uci.edu/~cjmayer/LSCI_202A/finnish.txt"))
uyghur <- read.table(url("http://socsci.uci.edu/~cjmayer/LSCI_202A/uyghur.txt"))
finnish$V1 %>%
get_cooccurrence_proportion(c('y', 'Ã¶', 'Ã¤'), c('u', 'o', 'a'))
get_cooccurrence_tokens(finnish, c('y', 'Ã¶', 'Ã¤'), c('u', 'o', 'a'))
finnish
typeof(finnish)
get_cooccurrence_tokens <- function(corpus, set1, set2){
re1 <- str_glue("[{str_c(set1, collapse='')}]")
re2 <- str_glue("[{str_c(set2, collapse='')}]")
corpus %>%
str_subset(re1) %>%
str_subset(re2)
}
get_cooccurence_tokens(finnish, c('y', 'ö', 'ä'), c('u', 'o', 'a'))
get_cooccurrence_tokens <- function(corpus, set1, set2){
re1 <- str_glue("[{str_c(set1, collapse='')}]")
re2 <- str_glue("[{str_c(set2, collapse='')}]")
corpus %>%
str_subset(re1) %>%
str_subset(re2)
}
# Q4.2
get_cooccurrence_proportion <- function(corpus, set1, set2){
length(get_cooccurrence_tokens(corpus, set1, set2)) / length(corpus)
}
# Q4.3
finnish <- read.table(url("http://socsci.uci.edu/~cjmayer/LSCI_202A/finnish.txt"))
uyghur <- read.table(url("http://socsci.uci.edu/~cjmayer/LSCI_202A/uyghur.txt"))
finnish$V1 %>%
get_cooccurrence_proportion(c('y', 'ö', 'ä'), c('u', 'o', 'a'))
uyghur$V1 %>%
get_cooccurrence_proportion(c('ü', 'ö', 'e'), c('u', 'o', 'a'))
finnish <- read.table(url("http://socsci.uci.edu/~cjmayer/LSCI_202A/finnish.txt"), encoding='UTF-8')
uyghur <- read.table(url("http://socsci.uci.edu/~cjmayer/LSCI_202A/uyghur.txt"), encoding='UTF-8')
finnish$V1 %>%
get_cooccurrence_proportion(c('y', 'ö', 'ä'), c('u', 'o', 'a'))
uyghur$V1 %>%
get_cooccurrence_proportion(c('ü', 'ö', 'e'), c('u', 'o', 'a'))
get_cooccurence_tokens(finnish$V1, c('y', 'ö', 'ä'), c('u', 'o', 'a'))
get_cooccurrence_tokens(finnish$V1, c('y', 'ö', 'ä'), c('u', 'o', 'a'))
bar <- get_cooccurrence_tokens(finnish$V1, c('y', 'ö', 'ä'), c('u', 'o', 'a'))
length(bar)
bar <- get_cooccurrence_tokens(uyghur$V1, c('ü', 'ö', 'e'), c('u', 'o', 'a'))
length(bar)
?get_cooccurrence_tokens
get_cooccurrence_tokens
# Returns disharmonic roots
get_cooccurence_tokens <-function(corpus,set1,set2){
# create regex patterns
set1_str <- str_c(set1,collapse='')
set1_pattern <- str_glue('[{set1_str}]')
set2_str <- str_c(set2,collapse='')
set2_pattern <- str_glue('[{set2_str}]')
# load corpus
corpus_data <- read_csv(corpus,col_names=c('words'))
# extract disharmonic roots into a vector
disharmonic_roots <- corpus_data %>%
filter(str_detect(words,set1_pattern) & str_detect(words,set2_pattern)) %>%
pull(words)
return(disharmonic_roots)
}
# Returns proportion of disharmonic roots in the corpus
get_cooccurence_proportion <- function(corpus,set1,set2){
# load corpus
corpus_data <- read_csv(corpus,col_names=c('words'))
C = dim(corpus_data)[1]
# get disharmonic roots
disharmonic_roots <- get_cooccurence_tokens(corpus,set1,set2)
d = length(disharmonic_roots)
# compute proportion
proportion_disharmonic <- d/C
return(proportion_disharmonic)
}
# Finnish
Finnish_corpus <- 'http://socsci.uci.edu/~cjmayer/LSCI_202A/finnish.txt'
# Front vowels in Finnish
set1 <- c('y','ö','ä')
# Back vowels in Finnish
set2 <- c('u','o','a')
Finnish_disharmonic_roots <- get_cooccurence_tokens(Finnish_corpus,set1,set2)
Finnish_disharmonic_proportion <- get_cooccurence_proportion(Finnish_corpus,set1,set2)
print(Finnish_disharmonic_proportion)
# Uyghur
Uyghur_corpus <- 'http://socsci.uci.edu/~cjmayer/LSCI_202A/uyghur.txt'
# Front vowels in Uyghur
set1 <- c('ü','ö','e')
# Back vowels in Uyghur
set2 <- c('u','o','a')
Uyghur_disharmonic_roots <- get_cooccurence_tokens(Uyghur_corpus,set1,set2)
Uyghur_disharmonic_proportion <- get_cooccurence_proportion(Uyghur_corpus,set1,set2)
print(Uyghur_disharmonic_proportion)
??knitr::opts_chunk
cars
geom_scatter
library(tidyverse)
geom_pocars
cars
install.packages("blogdown")
blogdown::install_hugo()
blogdown::install_hugo()
blogdown::install_hugo()
blogdown::install_hugo()
library(tidyverse)
data <- read_csv("C:/Users/conno/Dropbox/ling/megha_grant/distributional_learning/code/output.csv")
data <- data %>%
mutate(CosSimQuart = cut(data$CosSim, 4, labels=c('1', '2', '3', '4')),
PCACosSimQuart = cut(data$PCACosSim, 4, labels=c('1', '2', '3', '4')),
FeatCosSimQuart = cut(data$FeatCosSim, 4, labels=c('1', '2', '3', '4'))
)
low_dist_low_phon <- data %>%
filter(PCACosSimQuart == 1 & FeatCosSimQuart == 1) %>%
arrange(PCACosSim)
low_dist_high_phon <- data %>%
filter(PCACosSimQuart %in% c(1,2) & FeatCosSimQuart %in% c(3,4)) %>%
arrange(Class)
high_dist_low_phon <- data %>%
filter(PCACosSimQuart %in% c(3) & FeatCosSimQuart %in% c(1)) %>%
arrange(PCACosSim)
high_dist_high_phon <- data %>%
filter(PCACosSimQuart %in% c(4) & FeatCosSimQuart %in% c(4)) %>%
arrange(PCACosSim)
high_dist_low_phon
order
high_dist_low_phon
data <- read_csv("C:/Users/conno/Dropbox/ling/megha_grant/ngram calculator/output.csv")
library(tidyverse)
data <- read_csv("C:/Users/conno/Dropbox/ling/megha_grant/ngram calculator/output.csv")
cor(uni_prob, pos_uni_freq)
cor(data$uni_prob, data$pos_uni_freq)
cor(data$bi_prob, data$pos_bi_freq)
library(tidyverse)
data <- read_csv("C:/Users/conno/Dropbox/ling/megha_grant/ngram calculator/output.csv")
data
cor(data[data$word_len == 3,]$bi_prob, data[data$word_len == 3,]$pos_bi_freq)
cor(data[data$word_len == 3,]$uni_prob, data[data$word_len == 3,]$pos_uni_freq)
cor(data[data$word_len == 2,]$uni_prob, data[data$word_len == 2,]$pos_uni_freq)
arrange
arrange(data, vl_score)
arrange(data, -vl_score)
arrange(data[data$word_len == 3,], -vl_score)
library(tidyverse)
data <- read_csv("C:/Users/conno/Dropbox/ling/megha_grant/ngram calculator/output.csv")
library(tidyverse)
data <- read_csv("C:/Users/conno/Dropbox/ling/megha_grant/ngram calculator/output.csv")
data
data %>% group_by(word_len) %>% mutate()
data %>% group_by(word_len) %>% mutate(foo = cor(bi_prob, pos_bi_freq))
data %>% group_by(word_len) %>% mutate(foo = cor(bi_prob, pos_bi_freq))
blah <- data %>% group_by(word_len) %>% mutate(foo = cor(bi_prob, pos_bi_freq))
blah
blah <- data %>% group_by(word_len) %>% summarize(foo = cor(bi_prob, pos_bi_freq))
blah
head(data)
correlations <- data %>%
group_by(word_len) %>%
summarize(
unigram_uniphone_cor = cor(uni_prob, pos_uni_freq)
bigram_biphone_cor = cor(bi_prob, pos_bi_freq))
correlations <- data %>%
group_by(word_len) %>%
summarize(
unigram_uniphone_cor = cor(uni_prob, pos_uni_freq),
bigram_biphone_cor = cor(bi_prob, pos_bi_freq))
correlations
write_csv(correlations, 'correlations.csv')
mean(correlations$unigram_uniphone_cor)
mean(correlations$bigram_biphone_cor)
mean(correlations$bigram_biphone_cor, na.rm=TRUE)
write_csv(correlations, 'C:/Users/conno/Dropbox/ling/megha_grant/ngram calculator/correlations.csv')
library(tidyverse)
data <- read_csv("C:/Users/conno/Dropbox/ling/megha_grant/ngram calculator/output_stimuli.csv")
correlations <- data %>%
group_by(word_len) %>%
summarize(
unigram_uniphone_cor = cor(uni_prob, pos_uni_freq),
bigram_biphone_cor = cor(bi_prob, pos_bi_freq)
)
write_csv(correlations, 'C:/Users/conno/Dropbox/ling/megha_grant/ngram calculator/correlations_stimuli.csv')
correlations
data
unique(data$word)
unique(data$word_length)
unique(data$word_len)
correlations
data
data[data$word_len == 2,]
data[data$word_len == 4,]
correlations <- data %>%
summarize(
unigram_uniphone_cor = cor(uni_prob, pos_uni_freq),
bigram_biphone_cor = cor(bi_prob, pos_bi_freq)
)
correlations
correlations <- data %>%
filter(word_len == 3) %>%
summarize(
unigram_uniphone_cor = cor(uni_prob, pos_uni_freq),
bigram_biphone_cor = cor(bi_prob, pos_bi_freq)
)
data[data$word_len == 3,]
data[data$word_len == 3 & is.na(bi_prob),]
data[data$word_len == 3 & is.na(data$bi_prob),]
data[is.na(data$bi_prob)]
data[is.na(data$bi_prob),]
data[is.na(data$uni_prob),]
data[is.na(data$pos_uni_freq),]
data[is.na(data$pos_bi_freq),]
library(tidyverse)
data <- read_csv("C:/Users/conno/Dropbox/ling/megha_grant/ngram calculator/output_stimuli.csv")
correlations <- data %>%
filter(word_len == 3) %>%
summarize(
unigram_uniphone_cor = cor(uni_prob, pos_uni_freq, na.rm=TRUE),
bigram_biphone_cor = cor(bi_prob, pos_bi_freq, na.rm=TRUE)
)
data
data[data$bi_prob == '-inf']
data[data$bi_prob == '-inf',]
data[data$bi_prob == -inf,]
data[data$word == 'Y AW T',]
data[data$bi_prob == -Inf,]
library(tidyverse)
data <- read_csv("C:/Users/conno/Dropbox/ling/megha_grant/ngram calculator/output_stimuli.csv")
correlations <- data %>%
filter(word_len == 3) %>%
summarize(
unigram_uniphone_cor = cor(uni_prob, pos_uni_freq),
bigram_biphone_cor = cor(bi_prob, pos_bi_freq)
)
write_csv(correlations, 'C:/Users/conno/Dropbox/ling/megha_grant/ngram calculator/correlations_stimuli.csv')
correlations
correlations <- data %>%
summarize(
unigram_uniphone_cor = cor(uni_prob, pos_uni_freq),
bigram_biphone_cor = cor(bi_prob, pos_bi_freq)
)
correlations
correlations <- data %>%
group_by(word_len) %>%
summarize(
unigram_uniphone_cor = cor(uni_prob, pos_uni_freq),
bigram_biphone_cor = cor(bi_prob, pos_bi_freq)
)
correlations
library(tidyverse)
data <- read_csv("C:/Users/conno/Dropbox/ling/megha_grant/ngram calculator/output_stimuli.csv")
correlations <- data %>%
filter(word_len == 3) %>%
summarize(
unigram_uniphone_cor = cor(uni_prob, pos_uni_freq),
bigram_biphone_cor = cor(bi_prob, pos_bi_freq)
)
write_csv(correlations, 'C:/Users/conno/Dropbox/ling/megha_grant/ngram calculator/correlations_stimuli.csv')
correlations
t.test
t.test(c(1,2,3), c(6,2,8))
?t.test
filename <- 'C:/Users/conno/Dropbox/ling/vowel_learning_project/Code/vowel_learners/outputs/spanish_ads_cds/ads_results_f1_f2.csv'
df <- read_csv(filename)
library(tidyverse)
df <- read_csv(filename)
df
df <- read_csv(filename)
df
ggplot(df, aes(x=f1, y=f2, group=learned_cats)) +
geom_point()
ggplot(df, aes(x=f1, y=f2, color=learned_cats)) +
geom_point()
ggplot(df, aes(x=f1, y=f2, color=as.factor(learned_cats))) +
geom_point()
filename <- 'C:/Users/conno/Dropbox/ling/vowel_learning_project/Code/vowel_learners/outputs/spanish_ads_cds/cds_results_f1_f2.csv'
df <- read_csv(filename)
ggplot(df, aes(x=f1, y=f2, color=as.factor(learned_cats))) +
geom_point()
ggplot(df, aes(x=f1, y=f2, color=as.factor(learned_cats))) +
geom_point(size=10)
ggplot(df, aes(x=f1, y=f2, color=as.factor(learned_cats))) +
geom_point(size=5)
ggplot(df, aes(x=f1, y=f2, color=as.factor(learned_cats))) +
geom_point(size=6)
ads <- read_csv(filename)
ggplot(ads, aes(x=f1, y=f2, color=as.factor(learned_cats))) +
geom_point(size=5)
filename <- 'C:/Users/conno/Dropbox/ling/vowel_learning_project/Code/vowel_learners/outputs/spanish_ads_cds/ads_results_f1_f2.csv'
ads <- read_csv(filename)
ggplot(ads, aes(x=f1, y=f2, color=as.factor(learned_cats))) +
geom_point(size=5)
ads_filename <- 'C:/Users/conno/Dropbox/ling/vowel_learning_project/Code/vowel_learners/outputs/spanish_ads_cds/ads_results_f1_f2.csv'
ads <- read_csv(ads_filename)
ggplot(ads, aes(x=f1, y=f2, color=as.factor(learned_cats))) +
geom_point(size=5)
cds_filename <- 'C:/Users/conno/Dropbox/ling/vowel_learning_project/Code/vowel_learners/outputs/spanish_ads_cds/cds_results_f1_f2.csv'
cds <- read_csv(cds_filename)
ggplot(cds, aes(x=f1, y=f2, color=as.factor(learned_cats))) +
geom_point(size=5)
ggplot(ads, aes(x=f2, y=f1, color=as.factor(learned_cats))) +
geom_point(size=5)
ggplot(cds, aes(x=f2, y=f1, color=as.factor(learned_cats))) +
geom_point(size=5)
ggplot(ads, aes(x=f2, y=f1, color=as.factor(learned_cats))) +
geom_point(size=5)
ggplot(cds, aes(x=f2, y=f1, color=as.factor(learned_cats))) +
geom_point(size=5) +
scale_x_reverse() +
scale_y_reverse()
ggplot(ads, aes(x=f2, y=f1, color=as.factor(learned_cats))) +
geom_point(size=5) +
scale_x_reverse() +
scale_y_reverse()
ggplot(ads, aes(x=f2, y=f1, color=as.factor(learned_cats))) +
geom_point(size=3) +
scale_x_reverse() +
scale_y_reverse()
ggplot(cds, aes(x=f2, y=f1, color=as.factor(learned_cats))) +
geom_point(size=3) +
scale_x_reverse() +
scale_y_reverse()
library(ellipse)
library(tidyverse)
setwd('C:/Users/conno/Dropbox/ling/vowel_learning_project/Code/vowel_learners/outputs/spanish_ads_cds/')
ads_filename <- 'ads_results_f1_f2.csv'
ads <- read_csv(ads_filename)
ggplot(ads, aes(x=f2, y=f1, color=as.factor(learned_cats))) +
geom_point(size=3) +
scale_x_reverse() +
scale_y_reverse()
ads_mu_file <- 'ads_mus.csv'
ads_mus <- read_csv(ads_mu_file, col_names=FALSE)
ads_cov_file <- 'ads_covs.csv'
ads_covs <- read_csv(ads_cov_file, col_names=FALSE)
library(ellipse)
library(tidyverse)
setwd('C:/Users/conno/Dropbox/ling/vowel_learning_project/Code/vowel_learners/outputs/spanish_ads_cds/')
ads_filename <- 'ads_results_f1_f2.csv'
ads <- read_csv(ads_filename)
ggplot(ads, aes(x=f2, y=f1, color=as.factor(learned_cats))) +
geom_point(size=3) +
scale_x_reverse() +
scale_y_reverse()
ads_mu_file <- 'ads_mus.csv'
ads_mus <- read_csv(ads_mu_file, col_names=FALSE)
ads_cov_file <- 'ads_covs.csv'
ads_covs <- read_csv(ads_cov_file, col_names=FALSE)
ggplot(data=ads_mus, aes(x=X2, y=X1)) +
geom_point(size=3) +
scale_x_reverse() +
scale_y_reverse()
graph <- ggplot()
for (i in 1:nrow(ads_covs)) {
cov <- matrix(as.numeric(ads_covs[i,]), ncol=2) / nrow(ads %>% filter(learned_cats == i - 1))
el <- ellipse(cov, centre=matrix(as.numeric(ads_mus[i,])))
graph <- graph + geom_point(data=as_tibble(el), aes(x=y, y=x))
graph
}
graph +
scale_x_reverse() +
scale_y_reverse()
cds_filename <- 'cds_results_f1_f2.csv'
cds <- read_csv(cds_filename)
ggplot(cds, aes(x=f2, y=f1, color=as.factor(learned_cats))) +
geom_point(size=3) +
scale_x_reverse() +
scale_y_reverse()
cds_mu_file <- 'cds_mus.csv'
cds_mus <- read_csv(cds_mu_file, col_names=FALSE)
cds_cov_file <- 'cds_covs.csv'
cds_covs <- read_csv(cds_cov_file, col_names=FALSE)
file <- 'C:/Users/conno/Dropbox/ling/vowel_learning_project/Code/vowel_learners/corpus_data/sp_ids_f1_f2.csv'
foo <- read_csv(file)
ggplot(data=foo) +
geom_point(aes(x=f1, y=f2, color=vowel)) +
facet_grid(~ register) +
ggtitle("Spanish")
ggplot(data=foo) +
geom_point(aes(x=f1, y=f2, color=vowel), size=3) +
facet_grid(~ register) +
ggtitle("Spanish")
ggplot(data=foo) +
geom_point(aes(x=f1, y=f2, color=vowel), size=3) +
facet_grid(~ speaker) +
ggtitle("Spanish")
